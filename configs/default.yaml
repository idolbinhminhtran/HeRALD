# Optimized configuration for 4x RTX 5090 + 64-core CPU server

model:
  emb_dim: 512               # Large embedding for RTX 5090 memory
  num_layers: 4               # Deep but not too deep for stability
  dropout: 0.25               # Moderate dropout for regularization
  num_heads: 16               # Many heads for RTX 5090 compute power
  relation_dropout: 0.1       # Light relation dropout
  use_layernorm: true         # Use LayerNorm for stable training
  use_residual: true          # Use residual connections

training:
  lr: 3e-4                    # Optimized for large batch training
  weight_decay: 1e-5          # Moderate weight decay
  batch_size: 2048            # Large batch for 4x RTX 5090
  num_epochs: 100             # Moderate epochs with early stopping
  val_split: 0.15             # Standard validation split
  early_stopping_patience: 20 # Reasonable patience
  neg_ratio: 5                # Good negative sampling
  cosine_tmax: 100            # Match epochs for cosine annealing
  use_focal_loss: true        # Handle class imbalance
  label_smoothing: 0.1        # Regularization
  gradient_clip: 1.0          # Gradient clipping for stability

evaluation:
  loocv_epochs: 30            # More epochs for thorough LOOCV
  loocv_batch_size: 1024      # Large batch for RTX 5090 LOOCV
  loocv_lr: 2e-4              # Slightly lower LR for LOOCV
  loocv_neg_ratio: 5          # Match training neg_ratio

data:
  threshold: 0.0
  symmetric: true
  data_dir: Dataset
  sim_row_normalize: true     # Normalize similarity matrices
  sim_topk: 20                # Optimal connectivity

system:
  device: auto                # Auto-detect best GPU
  seed: 42                    # Random seed
  num_workers: 32             # Many workers for 64-core CPU
  use_amp: true               # Enable AMP for RTX 5090
  pin_memory: true            # Pin memory for faster GPU transfer
  prefetch_factor: 4          # Prefetch batches for efficiency